name: kadin-canta-test-1
on:
  workflow_dispatch:
    inputs:
      site_limit:
        description: 'Limit the number of sites to run for testing (optional)'
        required: false
        type: number
        default: 0 # 0 means no limit
  schedule:
    - cron: '0 5 * * 1'

env:
  MONGODB_URL: ${{secrets.MONGODB_URL}}
  GH_TOKEN: ${{secrets.GH_TOKEN}}
  GOOGLE_SERVICE_ACCOUNT_CREDENTIALS: ${{secrets.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS}}
  GOOGLE_SHEET_ID: ${{secrets.GOOGLE_SHEET_ID}}
  GOOGLE_SHEET_ID_FOR_LOGS: ${{secrets.GOOGLE_SHEET_ID_FOR_LOGS}}

jobs:
  prepare_matrix:
    runs-on: ubuntu-latest
    outputs:
      sites: ${{ steps.set-matrix.outputs.sites }}
      has-sites: ${{ steps.set-matrix.outputs.has-sites }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm install googleapis
      
      - name: Create package.json for CommonJS
        run: |
          cat > package.json << 'EOF'
          {
            "type": "commonjs"
          }
          EOF
      
      - name: Fetch sheet data and prepare matrix
        id: set-matrix
        env:
          SITE_LIMIT: ${{ github.event.inputs.site_limit }}
        run: |
          cat > fetch_data.js << 'EOF'
          const { google } = require('googleapis');
          const fs = require('fs');

          async function fetchAllSheetData() {
            try {
              console.log('ðŸ” Starting Google Sheets data fetch...');

              if (!process.env.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS) throw new Error('GOOGLE_SERVICE_ACCOUNT_CREDENTIALS not set');
              if (!process.env.GOOGLE_SHEET_ID) throw new Error('GOOGLE_SHEET_ID not set');

              const decodedCredentials = Buffer.from(process.env.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS, 'base64').toString('utf8');
              const credentials = JSON.parse(decodedCredentials);

              const auth = new google.auth.GoogleAuth({
                credentials,
                scopes: ['https://www.googleapis.com/auth/spreadsheets.readonly'],
              });

              const sheets = google.sheets({ version: 'v4', auth });
              const response = await sheets.spreadsheets.values.get({
                spreadsheetId: process.env.GOOGLE_SHEET_ID,
                range: 'wbags-scroll!A:K',
              });

              const rows = response.data.values;
              if (!rows || rows.length < 2) return { sites: [], sheetData: null };

              const dataRows = rows.slice(1);
              const sites = [];
              const siteLimit = process.env.SITE_LIMIT ? parseInt(process.env.SITE_LIMIT, 10) : 0;
              let sitesAdded = 0;

              for (let i = 0; i < dataRows.length; i++) {
                if (siteLimit > 0 && sitesAdded >= siteLimit) break;

                const row = dataRows[i];
                const brandName = row[0];
                const isPaused = row[8];

                if (brandName && brandName.trim() && brandName.toLowerCase() !== 'brands' &&
                    isPaused !== 'TRUE' && isPaused !== 'true') {
                  sites.push(brandName.trim());
                  sitesAdded++;
                }
              }

              const sheetData = { timestamp: new Date().toISOString(), runId: process.env.GITHUB_RUN_ID || 'local', data: rows };
              fs.writeFileSync('sheet-data.json', JSON.stringify(sheetData, null, 2));
              return { sites, sheetData };
            } catch (error) {
              console.error(error);
              process.exit(1);
            }
          }

          fetchAllSheetData().then(result => {
            const sitesJson = JSON.stringify(result.sites);
            const hasSites = result.sites.length > 0 ? 'true' : 'false';
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `sites=${sitesJson}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `has-sites=${hasSites}\n`);
          }).catch(error => {
            console.error(error);
            process.exit(1);
          });
          EOF

          node fetch_data.js

      - name: Upload sheet data artifact
        uses: actions/upload-artifact@v4
        with:
          name: sheet-data
          path: sheet-data.json
          retention-days: 1

  dizitv_job:
    needs: prepare_matrix
    if: needs.prepare_matrix.outputs.has-sites == 'true'
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix:
        site: ${{ fromJSON(needs.prepare_matrix.outputs.sites) }}
    uses: ./.github/workflows/reusableProdPuppeteer.yml
    with:
      site: ${{ matrix.site }}
    secrets: inherit

  summary:
    needs: [prepare_matrix, dizitv_job]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Job Summary
        run: |
          echo "## Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Sites Found | ${{ needs.prepare_matrix.outputs.has-sites == 'true' && 'Yes' || 'No' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Matrix Job Status | ${{ needs.dizitv_job.result }} |" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.prepare_matrix.outputs.has-sites }}" == "false" ]]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸ **No sites were found to process. Check your Google Sheet configuration.**" >> $GITHUB_STEP_SUMMARY
          fi

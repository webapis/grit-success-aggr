name: kadin-canta-test-1
on:
   workflow_dispatch:
   schedule:
     - cron: '0 5 * * 1'

env:
  MONGODB_URL: ${{secrets.MONGODB_URL}}
  GH_TOKEN: ${{secrets.GH_TOKEN}}
  GOOGLE_SERVICE_ACCOUNT_CREDENTIALS: ${{secrets.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS}}
  GOOGLE_SHEET_ID: ${{secrets.GOOGLE_SHEET_ID}}

jobs:
  prepare_matrix:
    runs-on: ubuntu-latest
    outputs:
      sites: ${{ steps.set-sites.outputs.sites }}
      sheet-data: ${{ steps.fetch-data.outputs.sheet-data }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm install googleapis
      
      - name: Create package.json for CommonJS
        run: |
          cat > package.json << 'EOF'
          {
            "type": "commonjs"
          }
          EOF
      
      # Fetch ALL sheet data once and cache it
      - name: Fetch sheet data
        id: fetch-data
        run: |
          cat > fetch_data.js << 'EOF'
          const { google } = require('googleapis');
          const fs = require('fs');
          
          async function fetchAllSheetData() {
            try {
              if (!process.env.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS) {
                throw new Error('GOOGLE_SERVICE_ACCOUNT_CREDENTIALS environment variable is not set');
              }
              
              if (!process.env.GOOGLE_SHEET_ID) {
                throw new Error('GOOGLE_SHEET_ID environment variable is not set');
              }
              
              const decodedCredentials = Buffer.from(process.env.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS, 'base64').toString('utf8');
              const credentials = JSON.parse(decodedCredentials);
              
              const auth = new google.auth.GoogleAuth({
                credentials: credentials,
                scopes: ['https://www.googleapis.com/auth/spreadsheets.readonly'],
              });
              
              const sheets = google.sheets({ version: 'v4', auth });
              
              // Fetch ALL data from the sheet (A:K columns)
              const response = await sheets.spreadsheets.values.get({
                spreadsheetId: process.env.GOOGLE_SHEET_ID,
                range: 'wbags-scroll!A:K',
              });
              
              const rows = response.data.values;
              if (!rows || rows.length === 0) {
                return { sites: [], sheetData: null };
              }
              
              // Extract sites (skip header, get non-paused sites)
              const dataRows = rows.slice(1);
              const sites = dataRows
                .filter(row => {
                  const brandName = row[0];
                  const isPaused = row[8]; // Column I (paused)
                  
                  return brandName && 
                         brandName.trim() !== '' && 
                         brandName.toLowerCase() !== 'brands' &&
                         isPaused !== 'TRUE';
                })
                .map(row => row[0].trim());
              
              // Prepare sheet data for sharing
              const sheetData = {
                timestamp: new Date().toISOString(),
                runId: process.env.GITHUB_RUN_ID || 'local',
                data: rows
              };
              
              // Save to file for artifact upload
              fs.writeFileSync('sheet-data.json', JSON.stringify(sheetData, null, 2));
              
              return { sites, sheetData };
            } catch (error) {
              console.error('Error fetching data from Google Sheets:', error.message);
              process.exit(1);
            }
          }
          
          fetchAllSheetData().then(result => {
            // Output sites for matrix
            console.log(`sites=${JSON.stringify(result.sites)}`);
            // Save sheet data as base64 for output (GitHub Actions has size limits)
            const sheetDataB64 = Buffer.from(JSON.stringify(result.sheetData)).toString('base64');
            console.log(`sheet-data=${sheetDataB64}`);
          }).catch(error => {
            console.error('Promise Error:', error.message);
            process.exit(1);
          });
          EOF
          
          node fetch_data.js >> $GITHUB_OUTPUT

      # Upload sheet data as artifact for other jobs to download
      - name: Upload sheet data artifact
        uses: actions/upload-artifact@v4
        with:
          name: sheet-data
          path: sheet-data.json
          retention-days: 1

      - name: Set sites output
        id: set-sites
        run: echo "Sites prepared for matrix execution"

  dizitv_job:
    needs: prepare_matrix
    strategy:
      fail-fast: false
      matrix:
        site: ${{ fromJSON(needs.prepare_matrix.outputs.sites) }}
    uses: ./.github/workflows/reusableProdPuppeteer.yml
    with:
      site: ${{ matrix.site }}
      sheet-data: ${{ needs.prepare_matrix.outputs.sheet-data }}
    secrets: inherit